# Final_project
The project does development and utilization of machine learning models for medical diagnosis necessitates a high level of professional proficiency.
Brain tumors pose a substantial health risk, and timely identification is imperative to enhance patient prognoses. Medical imaging techniques, such as magnetic resonance imaging (MRI), offer significant diagnostic insights into tumors.
The core aim of this project is to leverage the power of machine learning and deep learning models to enhance the classification and segmentation of brain tumors. The research is structured around four primary objectives. Initially, there is a focus on preprocessing the MRI datasets to extract meaningful features by standardizing the data and using data augmentation techniques, preparing the data for subsequent tasks. The project then dives into the classification of brain tumors, exploring a range of models from Random Forests to Convolutional Neural Networks. Following this, there is a creation and fine-tuning of segmentation models like U-Net and DeepLab to achieve precise demarcation of tumor boundaries. The final stage involves a comparative study of the models, evaluating them on multiple fronts like accuracy and computational efficiency.

Dataset: 
The dataset is collected from Kaggle website. The dataset has MRI images of approximately more than 100 patients.

CNN:
Convolutional Neural Networks (CNNs) is used to categorize the brain MRI images. The dataset are preprocessed and separated into training, validation, and test sets (more precisely, the FLAIR series brain MR images). To maximize the efficiency of the model, images are normalized and downsized to 256 by 256 pixels. TensorFlow is used in the construction of the CNN model, enabling it to process 256x256 images over three color channels. The model includes many convolutional layers with batch normalization, max-pooling, and dropout strategies to prevent overfitting. By optimizing the binary classification problem with the Adam optimizer and a suitable loss function, the model can handle big datasets with ease. Techniques that track validation loss and modify the learning process in response, such as early stopping, learning rate reduction, and model checkpointing, serve as a guidance for training. Accuracy metrics, confusion matrices, and classification reports are used to analyze the final model's performance, giving rise to a thorough evaluation of the CNN's capacity to effectively segment and categorize brain tumors.

RANDOM FOREST:
Using Scikit-learn, the Random Forest model is incorporated into the project to guarantee a classification procedure. To support both classical machine learning and deep learning, the required libraries, such as Scikit-learn and TensorFlow, are first imported.
The dataset is handled methodically after being saved in the designated directory. To extract images from the binary masks that correspond to them, image paths are gathered, and files are filtered. Using a custom method called extract_label, images are automatically labeled according to their filename and placed into either positive or negative classes. Next, using train_test_split from Scikit-learn, these labeled images are divided into training, validation, and test sets, guaranteeing a random and balanced distribution of the data. To enable uniform data scaling, images go through preprocessing, where they are normalized and scaled to 256x256 pixels. To provide interoperability with Random Forest models, each 2D image is converted into a 1D array, as these models require 1D data input. 

UNET:
The MRI pictures and masks that go with them make up the dataset. To confirm that the data is suitable for segmentation, the notebook makes sure that the MRI pictures and masks are loaded and shown correctly. To comprehend the composition and guarantee balanced training, it additionally looks at the class distribution within the dataset. A symmetric encoder-decoder structure is a component of the U-Net architecture. To forecast precise segmentation masks, the decoder restores the spatial dimensions that the encoder compressed to capture context. Throughout the training process, the U-Net model iteratively processes ground truth masks and MRI images to improve its predictions for accurate segmentation outputs. U-Net is very good at brain MRI segmentation because of its architecture, which excels at capturing minute details.

DEEPLAB:
Brain MRI images are segmented using the DeepLab model, which focuses on optimizing its parameters to reduce differences between predicted segmentations and real ground truth annotations. Gathering the dataset from Google Drive and using cloud storage to ensure data integrity are the first steps in the project. The notebook extracts the dataset for preprocessing and installs the required dependencies. The data is divided into test, training, and validation sets so that the model can evaluate robustness, learn generalized patterns, and validate learning with new data. TensorFlow and OpenCV are two of the libraries imported by the project to conduct picture preprocessing and model training. Using the provided dataset, DeepLab's architecture—integrated with GPU support for hardware acceleration—is trained. By monitoring the model's development with validation data, overfitting is avoided, and strong generalization is ensured. Effective picture segmentation and dependable model performance are guaranteed by this methodical technique.

Best model for classification and segmentation:
Classification: The Random Forest model works well for classification, especially when the objective is to classify images according to criteria, because it is generally easier to understand and can function well with less data.

Segmentation: The best model for segmentation tasks, particularly in medical imaging, is U-Net. Its architecture is especially useful for separating brain malignancies from MRI images since it is made to capture minute details and restore spatial resolution.
